---
title: "Final Project"
author: "Jordan Denish and Malcolm Mashig"
date: "5/7/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Generate a publishable Rmarkdown document with the following sections:

# Introduction

For this final project, we want to create an interactive data visualization for a Capstone group project that we worked on throughout the semester. We have developed a Shiny Application on R using the information from class lectures and teaching ourselves how Shiny works online. 

## Question and background information on the data and why you are asking this question(s).  References to previous research/evidence generally would be nice to include.

For our capstone project, we wanted to analyze Major League Baseball, hoping to use historical data and various statistics in order to predict player value and make conclusions about the sport. We narrowed our focus to be more specific, ultimately choosing to analyze and project future performance of starting pitchers. Our inspiration for picking this particular position came from the fact that starting pitchers have become increasingly important and prominent among playoff contending teams. The Washington Nationals, the winner of the 2019 World Series, for example, were anchored by three elite, highly-paid starting pitchers in Max Scherzer, Stephen Strasburg, and Patrick Corbin. 

Furthermore, the size and length of the contracts that teams are giving to starting pitchers are tremendously large. This past winter, during baseball’s free agency, over 1 billion dollar was spent on starting pitchers, the most free agency dollars spent on starting pitchers in baseball history. Free agent Gerrit Cole signed a nine-year, 324 million dollar contract with the New York Yankees, which is the largest deal ever signed by a pitcher. Gerrit Cole is currently 29 years old, which is considered to be one of the prime years for a starting pitcher, but he will be 38 years old at the end of his contract, when most pitchers are already in decline and considering retirement. Only the big market baseball teams like New York, Boston, and Philadelphia have the spending capabilities to afford these massive free agent signings, while the smaller market teams like Tampa Bay and Oakland must find cheap alternatives in order to be able to compete. This relatively recent trend in the importance that the sport is placing on finding valuable starting pitching led us to make it the concentration of our capstone project. 

After refining our ideas, we gathered the data relevant to our project. We took the approach of collecting a large amount of data, hoping this would help us further revise and pinpoint a particular question of interest. A website called FanGraphs was very helpful in this data collection process, containing seemingly every imaginable statistic for every player, separated by season. The site also provided the ability for us to filter the data based on position and various other criteria and easily export the data as a CSV formatted file. We decided to harvest all available starting pitcher data, with two significant constraints. First, we limited how far back our data went to the year 2002. Knowing that only somewhat recent data would be useful for drawing conclusions about the future, coupled with the fact that several advanced baseball metrics, such as xFIP and BABIP, have only been tracked since 2002, it made sense to cut the data off at this year. Our other constraint was that we limited the data to the seasons where the pitcher threw at least 80 innings. Though this admittedly is a somewhat arbitrary cutoff, our experimentation found that this excluded artificially short seasons, usually due to injury, while still providing a large amount of data to analyze. Further, after substantial back and forth consideration about whether to consider injuries, we decided not to pursue this analysis, as the extreme amount of randomness in injuries would likely prevent us from coming away with any meaningful results. Thus, our complete data set included all relevant performance statistics for each season with at least 80 innings pitched for every starting pitcher from 2002-2019. 

## Exploratory Data Analysis – Initial summary statistics and graphs with an emphasis on variables you believe to be important for your analysis.


## Research Question

	Once we were satisfied and confident in using xFIP as our performance metric, we were able to clearly state our research question: Can we accurately predict an MLB starting pitcher’s future xFIP over the next few seasons using various performance statistics from prior seasons in order to estimate relative future value of the pitcher? Simply put, we wanted to create a model that could take any pitcher, along with the statistics of all of their previous seasons, as an input and make projections for the xFIP of their next few seasons. From our main research question, two sub-questions naturally emerged as well. In particular, we wanted to look at how pitchers “aged”, or how their performance was affected as they got older, as well as whether all prior seasons were equally predictive or if more recent seasons were more important predictors of future xFIP. Our data set provided us with all of the relevant and necessary information to model xFIP over time, as well as answer our sub-questions. Further, viewing our data as a sample of the population of all starting pitcher seasons with at least 80 innings pitched, both past and future, we will be able to generalize our results to future seasons.



## Methods – Techniques you are using to address your question and the results of those methods.

In order to develop predictions for xFIP, we used a process named lagged linear regression. The theory of our lagged linear regression xFIP model is derived from the idea that in order to generate predictions for the next three years, we would want to produce incremental predictions. If we are looking at a pitcher's performance in 2019, we will first predict xFIP in 2020 and then use that prediction to generate our second prediction in 2021. Finally, we will use the prediction in 2021 to predict the pitcher’s xFIP value in 2022. 
Rather than using this same model to predict multiple years in advance, we used various “submodels” to predict each of these inputs for the next year, and then used these submodel predictions as inputs into our main model to predict the next year’s xFIP. 

For example, we could use additional predictors such as fastball velocity and fastball percentage (percentage of pitches that are fastballs) in 2019 to predict 2020’s xFIP; then, with our submodels, we could project each of the other unknown predictors that are inputs in our main model in 2020. We would then be able to plug these predicted values into our main model to predict 2021 xFIP and continue the process into the future. This is relevant because there were a large number of explanatory variables that could have potentially been used in our model, such as age, years of experience, or pitcher type, and would be known as predictions were made through the future. We can assume age increases by one each year, but we needed submodels that could estimate values for the explanatory variables that change from year to year and depend on additional inputs, such as fastball velocity. 

With this modeling process framework, we were able to predict standardized xFIP for a pitcher multiple years in the future. Once again, we predicted one year in the future, and then used the predicted xFIP value as input for the lagxFIP variable in order to predict the xFIP two years in the future. Each new year out that we predicted, we increased age by one and used the predictions for the last year (fastball velocity, fastball percentage, and xFIP) as input for the next round of submodel and model predictions. We planned to use the model to generate xFIP predictions for the next three seasons, 2020, 2021, and 2022. Going three seasons into the future paints a meaningful picture of the pitcher’s projected performance, and predicting any further resulted in increasingly reduced accuracy and higher variance.


## Conclusions – What can you say about the results of the methods section as it relates to your question.

	The table above displays our average residuals from using our training model to predict test data xFIP values. The above errors represent the average distance that the predictions are away from the actual xFIP values for each of the three seasons in the future. This means that on average, we would expect our test predictions for years 2020, 2021, and 2022 to be off by about 0.35, 0.44, and 0.48 from the actual xFIP values respectively. Since adding Models 2 and 3 and more years of data for each prediction, the error rates have reduced notably. We are pleased that these values are not much higher than our training absolute error, which means that we would expect our model to perform almost as well when predicting future xFIP values than the existing xFIP values. 


## Future work – What additional analysis is needed or what limited your analysis on this project.

```{r }

```
